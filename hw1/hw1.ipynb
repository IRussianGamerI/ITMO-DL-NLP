{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5761338a5a97c11",
   "metadata": {},
   "source": [
    "# Домашнее задание 1 $-$ 10 баллов\n",
    "Барабанщиков Лев Романович"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f9e75ce89af0e",
   "metadata": {},
   "source": [
    "1. Загрузите набор данных lenta-ru-news с помощью библиотеки Corus для задачи классификации текстов по топикам (пригодятся атрибуты title, text, topic)- 1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:58:25.106810Z",
     "start_time": "2025-09-18T20:57:24.116980Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-23 18:15:28--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-23T15%3A53%3A25Z&rscd=attachment%3B+filename%3Dlenta-ru-news.csv.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-23T14%3A53%3A02Z&ske=2025-09-23T15%3A53%3A25Z&sks=b&skv=2018-11-09&sig=rZEpKrZdMPo0xNionYaYppI4my4BoDE%2F8w6lJDHEriw%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1ODY0MDgyOCwibmJmIjoxNzU4NjQwNTI4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.7k8qtT46k9Cr337lGNx9xXL25o3GhmeN0Hp1ahGp-mw&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-09-23 18:15:28--  https://release-assets.githubusercontent.com/github-production-release-asset/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-23T15%3A53%3A25Z&rscd=attachment%3B+filename%3Dlenta-ru-news.csv.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-23T14%3A53%3A02Z&ske=2025-09-23T15%3A53%3A25Z&sks=b&skv=2018-11-09&sig=rZEpKrZdMPo0xNionYaYppI4my4BoDE%2F8w6lJDHEriw%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1ODY0MDgyOCwibmJmIjoxNzU4NjQwNTI4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.7k8qtT46k9Cr337lGNx9xXL25o3GhmeN0Hp1ahGp-mw&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 527373240 (503M) [application/octet-stream]\n",
      "Saving to: ‘lenta-ru-news.csv.gz’\n",
      "\n",
      "lenta-ru-news.csv.g 100%[===================>] 502.94M  26.3MB/s    in 20s     \n",
      "\n",
      "2025-09-23 18:15:48 (25.5 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08e328c2526e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:58:31.887559Z",
     "start_time": "2025-09-18T20:58:31.856828Z"
    }
   },
   "outputs": [],
   "source": [
    "from corus import load_lenta\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "records = load_lenta(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "125098ae779fedbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:58:36.200034Z",
     "start_time": "2025-09-18T20:58:36.194734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fff7b0d8cf67c6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:04.146154Z",
     "start_time": "2025-09-18T20:58:51.326519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "739351it [00:13, 56645.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "for record in tqdm(records):\n",
    "    if record.topic is None:\n",
    "        continue\n",
    "    data.append({\n",
    "        'title': record.title,\n",
    "        'text': record.text,\n",
    "        'topic': record.topic\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0ebe59739ebe12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:06.604221Z",
     "start_time": "2025-09-18T20:59:05.661048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Названы регионы России с самой высокой смертно...</td>\n",
       "      <td>Вице-премьер по социальным вопросам Татьяна Го...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Австрия не представила доказательств вины росс...</td>\n",
       "      <td>Австрийские правоохранительные органы не предс...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Обнаружено самое счастливое место на планете</td>\n",
       "      <td>Сотрудники социальной сети Instagram проанализ...</td>\n",
       "      <td>Путешествия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В США раскрыли сумму расходов на расследование...</td>\n",
       "      <td>С начала расследования российского вмешательст...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Хакеры рассказали о планах Великобритании зами...</td>\n",
       "      <td>Хакерская группировка Anonymous опубликовала н...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739346</th>\n",
       "      <td>Южно-Сахалинск объявлен очагом холеры</td>\n",
       "      <td>Сегодня областной центр Сахалина и Курил получ...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739347</th>\n",
       "      <td>Леворадикалы создают предвыборный блок</td>\n",
       "      <td>Бывший шеф Службы безопасности президента  Але...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739348</th>\n",
       "      <td>В горах Дагестана идут активные боевые действия</td>\n",
       "      <td>Сегодня утром в районах дагестанских селений Ч...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739349</th>\n",
       "      <td>Карачаево-Черкесия раскололась по национальном...</td>\n",
       "      <td>Намеченная на сегодняшний день церемония вступ...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739350</th>\n",
       "      <td>Коржаков готов рассказать Генпрокуратуре про ф...</td>\n",
       "      <td>На состоявшейся сегодня в Москве пресс-конфере...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739351 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0       Названы регионы России с самой высокой смертно...   \n",
       "1       Австрия не представила доказательств вины росс...   \n",
       "2            Обнаружено самое счастливое место на планете   \n",
       "3       В США раскрыли сумму расходов на расследование...   \n",
       "4       Хакеры рассказали о планах Великобритании зами...   \n",
       "...                                                   ...   \n",
       "739346              Южно-Сахалинск объявлен очагом холеры   \n",
       "739347             Леворадикалы создают предвыборный блок   \n",
       "739348    В горах Дагестана идут активные боевые действия   \n",
       "739349  Карачаево-Черкесия раскололась по национальном...   \n",
       "739350  Коржаков готов рассказать Генпрокуратуре про ф...   \n",
       "\n",
       "                                                     text        topic  \n",
       "0       Вице-премьер по социальным вопросам Татьяна Го...       Россия  \n",
       "1       Австрийские правоохранительные органы не предс...        Спорт  \n",
       "2       Сотрудники социальной сети Instagram проанализ...  Путешествия  \n",
       "3       С начала расследования российского вмешательст...          Мир  \n",
       "4       Хакерская группировка Anonymous опубликовала н...          Мир  \n",
       "...                                                   ...          ...  \n",
       "739346  Сегодня областной центр Сахалина и Курил получ...       Россия  \n",
       "739347  Бывший шеф Службы безопасности президента  Але...       Россия  \n",
       "739348  Сегодня утром в районах дагестанских селений Ч...       Россия  \n",
       "739349  Намеченная на сегодняшний день церемония вступ...       Россия  \n",
       "739350  На состоявшейся сегодня в Москве пресс-конфере...       Россия  \n",
       "\n",
       "[739351 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e32e35b2f12a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:13.371524Z",
     "start_time": "2025-09-18T20:59:13.335144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               160519\n",
       "Мир                  136680\n",
       "Экономика             79538\n",
       "Спорт                 64421\n",
       "Культура              53803\n",
       "Бывший СССР           53402\n",
       "Наука и техника       53136\n",
       "Интернет и СМИ        44675\n",
       "Из жизни              27611\n",
       "Дом                   21734\n",
       "Силовые структуры     19596\n",
       "Ценности               7766\n",
       "Бизнес                 7399\n",
       "Путешествия            6408\n",
       "69-я параллель         1268\n",
       "Крым                    666\n",
       "Культпросвет            340\n",
       "                        203\n",
       "Легпром                 114\n",
       "Библиотека               65\n",
       "Оружие                    3\n",
       "ЧМ-2014                   2\n",
       "МедНовости                1\n",
       "Сочи                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f1bc1299a4e97",
   "metadata": {},
   "source": [
    "2. Подготовьте данные к обучению: - 3 балла\n",
    "\n",
    "Предобработайте данные: реализуйте оптимальную, на ваш взгляд, предобработку текстов (нормализация, очистка, стемминг/лемматизация и т.п.) и таргета.\n",
    "\n",
    "Кратко опишите пайплайн, на котором остановились, и почему.\n",
    "\n",
    "Разделите датасет на обучающую, валидационную и тестовую выборки со стратификацией в пропорции 60/20/20. В качестве целевой переменной используйте атрибут `topic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79960d648648ca98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:25.321141Z",
     "start_time": "2025-09-18T20:59:21.454243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bitcoin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bitcoin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c871f0cfaf34a7b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:26.329430Z",
     "start_time": "2025-09-18T20:59:26.309909Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/bitcoin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8091d367dc9164ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:35.253680Z",
     "start_time": "2025-09-18T20:59:35.250087Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    # Очистка\n",
    "    text = re.sub(r'[^а-яёa-z\\s]|\\d+', '', text.lower())\n",
    "    tokens = word_tokenize(text, language = \"russian\")\n",
    "    # Лемматизация\n",
    "    tokens = [morph.parse(t)[0].normal_form for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77fd3def0e539fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:59:37.155992Z",
     "start_time": "2025-09-18T20:59:37.117227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230c1e8cf1c84ef0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-09-18T20:59:47.508854Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875d9a9c4deb4a7f9539e369e0a341ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=73936), Label(value='0 / 73936')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "df['processed_content'] = df['content'].parallel_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d9d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Память очищена\n",
      "Использование памяти процессом: 7625.25 MB\n"
     ]
    }
   ],
   "source": [
    "# Очистка памяти после обработки данных\n",
    "import gc\n",
    "\n",
    "# Удаляем исходные данные для освобождения памяти\n",
    "del data\n",
    "del records\n",
    "\n",
    "# Удаляем промежуточную колонку content, если она больше не нужна\n",
    "if 'content' in df.columns:\n",
    "    df.drop('content', axis=1, inplace=True)\n",
    "\n",
    "# Принудительный запуск сборщика мусора\n",
    "gc.collect()\n",
    "\n",
    "print(\"Память очищена\")\n",
    "\n",
    "# Проверяем использование памяти\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "print(f\"Использование памяти процессом: {memory_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4f428a6338c64",
   "metadata": {},
   "source": [
    "**Описание пайплайна:** Текст из колонок title и text объединяется в единую колонку content. Далее каждый текст проходит через несколько этапов предобработки:\n",
    "1. приведение к нижнему регистру;\n",
    "2. фильтрация символов, не являющихся буквами или пробелами;\n",
    "3. токенизация, удаление стоп-слов и коротких токенов\n",
    "4. лемматизация $-$ приведение слов к нормальной форме.\n",
    "\n",
    "Обработанные тексты сохраняются в новой колонке processed_content.\n",
    "Для распараллеливания процесса используется библиотека pandarallel с прогресс-баром"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d287b39efd07f20",
   "metadata": {},
   "source": [
    "Разделение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbdd705d1404e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:17:19.874321Z",
     "start_time": "2025-03-04T21:17:18.304163Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['processed_content']\n",
    "y = df['topic']\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X, y, test_size=0.4, random_state=777)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_other, y_other, test_size=0.5, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d49d486a49f161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:17:45.999859Z",
     "start_time": "2025-03-04T21:17:45.995988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443610,) (147870,) (147871,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92672ba16525471",
   "metadata": {},
   "source": [
    "3. Замерьте базовое качество с любым dummy-бейзлайном $-$ 0.5 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1023cbf58aadae8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:26:58.311635Z",
     "start_time": "2025-03-04T21:26:57.891307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на бейзлайне: 0.2168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=777)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_valid_pred_dummy = dummy.predict(X_valid)\n",
    "print(f'Точность на бейзлайне: {accuracy_score(y_valid, y_valid_pred_dummy):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928d17396a1129b",
   "metadata": {},
   "source": [
    "4. Обучите модель sklearn.linear_model.LogisticRegression с двумя вариантами векторизации: 2 балла\n",
    "- sklearn.feature_extraction.text.CountVectorizer\n",
    "- sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76d8d9ff011a3e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:31:07.543087Z",
     "start_time": "2025-03-04T21:27:56.499515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + LogReg accuracy: 0.8353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TF-IDF\n",
    "\n",
    "tfidf = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(max_features=10000)),\n",
    "    ('classify', LogisticRegression(max_iter=1000, random_state=777))\n",
    "])\n",
    "\n",
    "tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tfidf = tfidf.predict(X_valid)\n",
    "\n",
    "print(f'TF-IDF + LogReg accuracy: {accuracy_score(y_valid, y_pred_tfidf):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9129c2239a8b02c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T21:54:27.703719Z",
     "start_time": "2025-03-04T21:45:35.059265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer accuracy: 0.8192\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "count = Pipeline([\n",
    "    ('vectorize', CountVectorizer(max_features=10000)),\n",
    "    ('classify', LogisticRegression(max_iter=1000, random_state=777))\n",
    "])\n",
    "\n",
    "count.fit(X_train, y_train)\n",
    "\n",
    "y_pred_count = count.predict(X_valid)\n",
    "\n",
    "print(f'CountVectorizer accuracy: {accuracy_score(y_valid, y_pred_count):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8e21110bcf476",
   "metadata": {},
   "source": [
    "5. Попробуйте улучшить качество, подобрав оптимальные гиперпараметры трансформаций и модели на кросс-валидации 1 балл\n",
    "\n",
    "Переберем гиперпараметры с помощью GridSearchCV: диапазон n-грамм, количество признаков и параметр регуляризации C. Проведем кросс-валидация на 3 фолдах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64bcecbf77db3e8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-04T22:00:57.238724Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classify__C=0.1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 1); total time= 1.3min\n",
      "[CV] END classify__C=0.1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 1); total time= 1.3min\n",
      "[CV] END classify__C=1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 1); total time= 1.3min\n",
      "[CV] END classify__C=1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 1); total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classify__C=0.1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 2); total time= 2.5min\n",
      "[CV] END classify__C=0.1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 2); total time= 2.5min\n",
      "[CV] END classify__C=1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 2); total time= 2.4min\n",
      "[CV] END classify__C=1, classify__max_iter=100, vectorize__max_features=10000, vectorize__ngram_range=(1, 2); total time= 2.4min\n",
      "Best configuratiown: {'classify__C': 1, 'classify__max_iter': 100, 'vectorize__max_features': 10000, 'vectorize__ngram_range': (1, 1)}\n",
      "Best score: 0.8257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'vectorize__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorize__max_features': [10000],\n",
    "    'classify__C': [0.1, 1],\n",
    "    'classify__max_iter': [100]  # Уменьшим количество итераций для ускорения\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(tfidf, param_grid, cv=2, n_jobs=10, verbose=2)  # Запустим на 10 ядрах\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best configuratiown: {grid.best_params_}')\n",
    "print(f'Best score: {grid.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164727af",
   "metadata": {},
   "source": [
    "6. Оцените качество лучшего пайплайна на отложенной выборке - **0.5 балла**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd79e679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'classify__C': 1, 'classify__max_iter': 100, 'vectorize__max_features': 10000, 'vectorize__ngram_range': (1, 1)}\n",
      "Лучший скор на кросс-валидации: 0.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6029"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Лучшая модель из GridSearchCV\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Лучшие гиперпараметры:\", grid.best_params_)\n",
    "print(f\"Лучший скор на кросс-валидации: {grid.best_score_:.4f}\")\n",
    "6029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d179280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.8320\n",
      "\n",
      "Отчет о классификации:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00        36\n",
      "   69-я параллель       0.75      0.36      0.49       245\n",
      "       Библиотека       0.00      0.00      0.00        16\n",
      "           Бизнес       0.67      0.33      0.44      1453\n",
      "      Бывший СССР       0.84      0.86      0.85     10767\n",
      "              Дом       0.87      0.80      0.83      4338\n",
      "         Из жизни       0.69      0.64      0.66      5441\n",
      "   Интернет и СМИ       0.79      0.74      0.77      8988\n",
      "             Крым       0.49      0.24      0.33       143\n",
      "    Культпросвет        0.25      0.01      0.03        76\n",
      "         Культура       0.88      0.89      0.89     10732\n",
      "          Легпром       0.00      0.00      0.00        18\n",
      "              Мир       0.82      0.86      0.84     27609\n",
      "  Наука и техника       0.84      0.85      0.85     10502\n",
      "      Путешествия       0.81      0.62      0.70      1281\n",
      "           Россия       0.81      0.84      0.82     32225\n",
      "Силовые структуры       0.74      0.51      0.60      3977\n",
      "            Спорт       0.96      0.97      0.97     12761\n",
      "         Ценности       0.91      0.83      0.87      1551\n",
      "          ЧМ-2014       0.00      0.00      0.00         1\n",
      "        Экономика       0.84      0.88      0.86     15711\n",
      "\n",
      "         accuracy                           0.83    147871\n",
      "        macro avg       0.62      0.54      0.56    147871\n",
      "     weighted avg       0.83      0.83      0.83    147871\n",
      "\n",
      "\n",
      "Правильных предсказаний: 123025 из 147871\n",
      "Неправильных предсказаний: 24846\n",
      "\n",
      "Улучшение по сравнению с бейзлайном: 0.6152 (283.8% относительного улучшения)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bitcoin/ITMO/ITMO-DL-NLP/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Оценка качества на тестовой выборке\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Точность на тестовой выборке: {test_accuracy:.4f}\")\n",
    "\n",
    "# Подробный отчет о классификации\n",
    "print(\"\\nОтчет о классификации:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Количество правильных и неправильных предсказаний\n",
    "correct_predictions = (y_test == y_test_pred).sum()\n",
    "total_predictions = len(y_test)\n",
    "print(f\"\\nПравильных предсказаний: {correct_predictions} из {total_predictions}\")\n",
    "print(f\"Неправильных предсказаний: {total_predictions - correct_predictions}\")\n",
    "\n",
    "# Сравнение с базовым качеством\n",
    "improvement = test_accuracy - 0.2168  # baseline accuracy\n",
    "print(f\"\\nУлучшение по сравнению с бейзлайном: {improvement:.4f} ({improvement/0.2168*100:.1f}% относительного улучшения)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a920c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего классов в тестовой выборке: 21\n",
      "\n",
      "Топ-5 худших классов по точности:\n",
      ": 0.0000 (36 образцов)\n",
      "Легпром: 0.0000 (18 образцов)\n",
      "Библиотека: 0.0000 (16 образцов)\n",
      "ЧМ-2014: 0.0000 (1 образцов)\n",
      "Культпросвет : 0.0132 (76 образцов)\n",
      "\n",
      "Топ-5 лучших классов по точности:\n",
      "Мир: 0.8561 (27609 образцов)\n",
      "Бывший СССР: 0.8572 (10767 образцов)\n",
      "Экономика: 0.8751 (15711 образцов)\n",
      "Культура: 0.8928 (10732 образцов)\n",
      "Спорт: 0.9704 (12761 образцов)\n"
     ]
    }
   ],
   "source": [
    "# Анализ ошибок по классам\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Получим уникальные классы и их количество\n",
    "unique_classes = y_test.unique()\n",
    "print(f\"Всего классов в тестовой выборке: {len(unique_classes)}\")\n",
    "\n",
    "# Посмотрим на распределение ошибок по классам\n",
    "class_accuracy = {}\n",
    "for cls in unique_classes:\n",
    "    mask = y_test == cls\n",
    "    if mask.sum() > 0:\n",
    "        cls_accuracy = accuracy_score(y_test[mask], y_test_pred[mask])\n",
    "        class_accuracy[cls] = cls_accuracy\n",
    "\n",
    "# Топ-5 лучших и худших классов по точности\n",
    "sorted_accuracy = sorted(class_accuracy.items(), key=lambda x: x[1])\n",
    "print(\"\\nТоп-5 худших классов по точности:\")\n",
    "for cls, acc in sorted_accuracy[:5]:\n",
    "    count = (y_test == cls).sum()\n",
    "    print(f\"{cls}: {acc:.4f} ({count} образцов)\")\n",
    "\n",
    "print(\"\\nТоп-5 лучших классов по точности:\")\n",
    "for cls, acc in sorted_accuracy[-5:]:\n",
    "    count = (y_test == cls).sum()\n",
    "    print(f\"{cls}: {acc:.4f} ({count} образцов)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77813b",
   "metadata": {},
   "source": [
    "## Выводы по оценке качества лучшего пайплайна\n",
    "\n",
    "**Лучший пайплайн:** TfidfVectorizer + LogisticRegression с оптимизированными гиперпараметрами\n",
    "\n",
    "**Основные результаты:**\n",
    "- Точность на тестовой выборке показывает стабильное качество модели\n",
    "- Значительное улучшение по сравнению с базовым бейзлайном (dummy classifier)\n",
    "- Модель показывает хорошую обобщающую способность на отложенных данных\n",
    "\n",
    "**Характеристики модели:**\n",
    "- Использует TF-IDF векторизацию для преобразования текста в числовые признаки\n",
    "- Логистическая регрессия как классификатор с оптимизированными гиперпараметрами\n",
    "- Предобработка включает лемматизацию, удаление стоп-слов и очистку текста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131afe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
