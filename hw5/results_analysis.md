| Метод               |   Accuracy |   Precision |   Recall |   F1 Score |   Время обучения (с) |   Память (МБ) |   Обучаемые параметры |   % параметров |
|:--------------------|-----------:|------------:|---------:|-----------:|---------------------:|--------------:|----------------------:|---------------:|
| Full Finetuning     |     0.928  |    0.928961 |   0.928  |   0.928072 |              367.541 |     846.153   |             109486854 |     100        |
| Peft Prompt         |     0.926  |    0.928101 |   0.926  |   0.926747 |              265.365 |       3.45947 |                446982 |       0.406592 |
| Peft Lora (rank=16) |     0.924  |    0.92482  |   0.924  |   0.924216 |              271.176 |       6.83447 |                889350 |       0.805744 |
| Linear Probing      |     0.5925 |    0.587101 |   0.5925 |   0.558515 |              135.918 |       4.08838 |                298374 |       0.271791 |

## Сравнительный анализ методов

### 1. Качество классификации

Лучший результат по F1-метрике показал метод **Full Finetuning** со значением **0.9281**.

- По сравнению с методом **Linear Probing** улучшение составляет **0.3696** (или **66.17%**)
- По сравнению с методом **Peft Lora** улучшение составляет **0.0039** (или **0.42%**)
- По сравнению с методом **Peft Prompt** улучшение составляет **0.0013** (или **0.14%**)

### 2. Эффективность обучения

Самым быстрым оказался метод **Linear Probing** со временем обучения **135.92 секунд**.

- **Peft Prompt** медленнее на **129.45 секунд** (или **95.24%**)
- **Peft Lora** медленнее на **135.26 секунд** (или **99.51%**)
- **Full Finetuning** медленнее на **231.62 секунд** (или **170.41%**)

### 3. Эффективность использования параметров

Наименьшее количество обучаемых параметров у метода **Linear Probing**: **298,374** параметров (**0.2718%** от общего числа).

- **Peft Prompt** использует на **148,608** параметров больше (**49.81%**), что составляет **0.4066%** от общего числа
- **Peft Lora** использует на **590,976** параметров больше (**198.07%**), что составляет **0.8057%** от общего числа
- **Full Finetuning** использует на **109,188,480** параметров больше (**36594.50%**), что составляет **100.0000%** от общего числа

### 4. Общие выводы

1. По балансу качества и эффективности лучшим методом является **Peft Prompt**.
2. **Рекомендации по выбору метода:**
   - При ограниченных вычислительных ресурсах: **Linear Probing**
   - При ограниченном времени обучения: **Linear Probing**
   - При приоритете качества модели: **Full Finetuning**

4. **Full finetuning** значительно превосходит **Linear Probing** по качеству, что указывает на важность обновления весов базовой модели для этой задачи.

### Заключение

Выбор метода дообучения трансформерной модели должен основываться на балансе между качеством классификации, вычислительными ресурсами и временем обучения. В данном сравнении наилучший компромисс между этими факторами обеспечивает метод **Peft Prompt**.